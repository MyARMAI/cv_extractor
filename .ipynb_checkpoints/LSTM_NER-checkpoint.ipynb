{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Govardhana</td>\n",
       "      <td>Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>K</td>\n",
       "      <td>Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Profil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Software</td>\n",
       "      <td>Profil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Profil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720759</th>\n",
       "      <td>28831</td>\n",
       "      <td>2013</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720760</th>\n",
       "      <td>28831</td>\n",
       "      <td>2013</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720761</th>\n",
       "      <td>28831</td>\n",
       "      <td>2010</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720762</th>\n",
       "      <td>28831</td>\n",
       "      <td>2015</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720763</th>\n",
       "      <td>28831</td>\n",
       "      <td>2013</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720764 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence #        Word     Tag\n",
       "0                0  Govardhana    Name\n",
       "1                0           K    Name\n",
       "2                0      Senior  Profil\n",
       "3                0    Software  Profil\n",
       "4                0    Engineer  Profil\n",
       "...            ...         ...     ...\n",
       "720759       28831        2013    Date\n",
       "720760       28831        2013    Date\n",
       "720761       28831        2010    Date\n",
       "720762       28831        2015    Date\n",
       "720763       28831        2013    Date\n",
       "\n",
       "[720764 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "filepath = u\"./resume_sentence_dataset_balanced.csv\"\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date tag to Date instead of 0\n",
    "#data.loc[data.index[data.Word.str.contains(\"[0-9]{4}$\")],'Tag'] = \"Date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email Address          65524\n",
       "O                      65524\n",
       "Profil                 65524\n",
       "Date                   65524\n",
       "Companies worked at    65524\n",
       "Location               65524\n",
       "Degree                 65524\n",
       "Duration               65524\n",
       "College Name           65524\n",
       "Skills                 65524\n",
       "Name                   65524\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email Address          65524\n",
       "O                      65524\n",
       "Profil                 65524\n",
       "Date                   65524\n",
       "Companies worked at    65524\n",
       "Location               65524\n",
       "Degree                 65524\n",
       "Duration               65524\n",
       "College Name           65524\n",
       "Skills                 65524\n",
       "Name                   65524\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## remove random O-Tag\n",
    "#import random\n",
    "import math\n",
    "\n",
    "index = data.index[data['Tag'] == \"O\"]\n",
    "O_tagSize = math.ceil((len(index)*0.9))\n",
    "\n",
    "drop_indices = np.random.choice(index, O_tagSize, replace=False)\n",
    "#data = data.drop(drop_indices)\n",
    "\n",
    "data[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w,t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            print(s)\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad word to a length of 50 (why ? Keras need to have same length for each input in the neural net)\n",
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "\n",
    "\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\",value=0)\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\",value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# change label to categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "\n",
    "#X = X.reshape(X.shape[0],X.shape[1],1)\n",
    "#y = y.reshape(y.shape[0],y.shape[1],1)\n",
    "#X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train (input & label) test (input & label)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 50)            736500    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 128)           58880     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 11)            1419      \n",
      "=================================================================\n",
      "Total params: 796,799\n",
      "Trainable params: 796,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=50, input_shape=(max_len,), input_length=max_len,mask_zero=True))# 50-dim embedding\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(units=64, return_sequences=True, recurrent_dropout=0.5)))  # variational biLSTM\n",
    "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))  # softmax output layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "!del /Q logs \n",
    "\n",
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18162 samples, validate on 7785 samples\n",
      "Epoch 1/10\n",
      "18162/18162 [==============================] - 57s 3ms/sample - loss: 0.0128 - accuracy: 0.9927 - val_loss: 0.0229 - val_accuracy: 0.9876\n",
      "Epoch 2/10\n",
      "18162/18162 [==============================] - 38s 2ms/sample - loss: 0.0115 - accuracy: 0.9932 - val_loss: 0.0214 - val_accuracy: 0.9883\n",
      "Epoch 3/10\n",
      "18162/18162 [==============================] - 35s 2ms/sample - loss: 0.0107 - accuracy: 0.9936 - val_loss: 0.0221 - val_accuracy: 0.9884\n",
      "Epoch 4/10\n",
      "18162/18162 [==============================] - 36s 2ms/sample - loss: 0.0100 - accuracy: 0.9938 - val_loss: 0.0216 - val_accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "18162/18162 [==============================] - 35s 2ms/sample - loss: 0.0095 - accuracy: 0.9941 - val_loss: 0.0221 - val_accuracy: 0.9882\n",
      "Epoch 6/10\n",
      "18162/18162 [==============================] - 36s 2ms/sample - loss: 0.0088 - accuracy: 0.9945 - val_loss: 0.0212 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "18162/18162 [==============================] - 37s 2ms/sample - loss: 0.0084 - accuracy: 0.9946 - val_loss: 0.0218 - val_accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "18162/18162 [==============================] - 47s 3ms/sample - loss: 0.0078 - accuracy: 0.9949 - val_loss: 0.0216 - val_accuracy: 0.9886\n",
      "Epoch 9/10\n",
      "18162/18162 [==============================] - 46s 3ms/sample - loss: 0.0075 - accuracy: 0.9951 - val_loss: 0.0218 - val_accuracy: 0.9885\n",
      "Epoch 10/10\n",
      "18162/18162 [==============================] - 36s 2ms/sample - loss: 0.0069 - accuracy: 0.9955 - val_loss: 0.0232 - val_accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = model.fit(X_tr, np.array(y_tr), batch_size=256, epochs=10, validation_split=0.3, callbacks=[tensorboard_callback], verbose=1,class_weight=value,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-eee16937d5a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist = pd.DataFrame(history.history)\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.plot(hist[\"acc\"],label=\"accuracy\")\n",
    "plt.plot(hist[\"val_acc\"],label=\"validation_acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884/2884 [==============================] - 3s 1ms/sample\n",
      "F1-score: 88.1%\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Email Address       0.98      0.99      0.98      6195\n",
      "               Date       0.97      0.95      0.96       281\n",
      "             Profil       0.92      0.93      0.92       297\n",
      "           Location       0.97      0.94      0.95       292\n",
      "             Skills       0.97      0.99      0.98      6858\n",
      "           Duration       0.00      0.00      0.00      2885\n",
      "               Name       0.86      0.93      0.90       288\n",
      "Companies worked at       0.91      0.90      0.91       286\n",
      "       College Name       0.90      0.93      0.91       294\n",
      "             Degree       0.94      0.94      0.94       302\n",
      "\n",
      "          micro avg       0.95      0.82      0.88     17978\n",
      "          macro avg       0.81      0.82      0.82     17978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_te,verbose=1)\n",
    "\n",
    "pred_labels = pred2label(y_pred)\n",
    "test_labels = pred2label(y_te)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
    " \n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 49\n",
    "p = model.predict(np.array([X_te[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "for w, pred in zip(X_te[i], p[0]):\n",
    "    print(\"{:15}: {}\".format(words[w], tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00375242 1.00847293 0.99949923 0.99110008 1.00162131 1.0007714\n",
      " 0.99235094 0.99360496 1.0046074  0.99612254 1.00847293]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "y_ints = [y.argmax() for y in y_tr]\n",
    "value = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_ints),\n",
    "                                                 y_ints)\n",
    "print(value)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=256, epochs=10, shuffle=True,validation_split=0.1, verbose=1,class_weight=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884/2884 [==============================] - 2s 712us/sample\n",
      "F1-score: 88.1%\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      Email Address       0.98      0.99      0.98      6195\n",
      "               Date       0.97      0.95      0.96       281\n",
      "             Profil       0.92      0.93      0.92       297\n",
      "           Location       0.97      0.94      0.95       292\n",
      "             Skills       0.97      0.99      0.98      6858\n",
      "           Duration       0.00      0.00      0.00      2885\n",
      "               Name       0.86      0.93      0.90       288\n",
      "Companies worked at       0.91      0.90      0.91       286\n",
      "       College Name       0.90      0.93      0.91       294\n",
      "             Degree       0.94      0.94      0.94       302\n",
      "\n",
      "          micro avg       0.95      0.82      0.88     17978\n",
      "          macro avg       0.81      0.82      0.82     17978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_te,verbose=1)\n",
    "\n",
    "pred_labels = pred2label(y_pred)\n",
    "test_labels = pred2label(y_te)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
    " \n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||Prediction\n",
      "==============================\n",
      "Developer      : Profil\n",
      "in             : O    \n",
      "HTML5          : Skills\n",
      ",              : O    \n",
      "JavaScript     : Skills\n",
      "and            : O    \n",
      "CSS3           : O    \n",
      "(Examen 70-480): O    \n",
      "Oracle         : O    \n",
      ".              : O    \n",
      "Developer      : Profil\n",
      "Java           : O    \n",
      "Programmer     : O    \n",
      "2012           : O    \n",
      "to             : O    \n",
      "2013           : O    \n"
     ]
    }
   ],
   "source": [
    "test_sentence = [\"Developer\" ,\"in\", \"HTML5\", \",\", \"JavaScript\", \"and\", \"CSS3\", \"(Examen 70-480)\"\n",
    "                ,\"Oracle\", \".\",\"Developer\" ,\"Java\", \"Programmer\",\"2012\",\"to\",\"2013\"]\n",
    "\n",
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)\n",
    "p = model.predict(np.array([x_test_sent[0]]))\n",
    "\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "print(30 * \"=\")\n",
    "for w, pred in zip(test_sentence, p[0]):\n",
    "    print(\"{:15}: {:5}\".format(w, tags[pred]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##F1 - Score : 88.1%\n",
    "model.save(\"saved_model/lstm_ner_model.h5\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
