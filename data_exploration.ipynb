{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 24\n"
     ]
    }
   ],
   "source": [
    "import textract\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#in case punkt package is missing decomment the line below\n",
    "#nltk.download(\"punkt\")\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "datadir = r\"C:\\Users\\Cheikh\\Desktop\\Projet_memoire\\myArmAi\\samples\\cv\\cv_atos\\fr\\word\"\n",
    "\n",
    "def loadData(path):\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "            raise Exception(\"OpenFolderException\",\"The given path is not a valid folder or folder doesn't exist\")\n",
    "    _dataset = []\n",
    "    raw_dataset = [textract.process(os.path.join(datadir,f)).decode() for f in os.listdir(datadir)]\n",
    "    \n",
    "    print(\"Dataset size : {}\".format(len(raw_dataset)))\n",
    "    \n",
    "    for d in raw_dataset:\n",
    "        _dataset.append(d)\n",
    "    return _dataset;\n",
    "\n",
    "\n",
    "def dataSetInfo(data):\n",
    "    word_count = 0;\n",
    "    for _d in data:\n",
    "        word_count += len(_d)\n",
    "    return word_count;\n",
    "\n",
    "dataset = loadData(datadir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdoulaye',\n",
       " 'barro',\n",
       " 'ingénieur',\n",
       " 'etude',\n",
       " 'développement',\n",
       " 'formation',\n",
       " '2018',\n",
       " 'master',\n",
       " 'big',\n",
       " 'data',\n",
       " 'aims',\n",
       " 'mbour',\n",
       " '2017',\n",
       " 'master',\n",
       " 'science',\n",
       " 'ingénieur',\n",
       " 'option',\n",
       " 'informatique',\n",
       " 'esp',\n",
       " '2015',\n",
       " 'master',\n",
       " 'statistique',\n",
       " 'appliquée',\n",
       " 'université',\n",
       " 'gaston',\n",
       " 'berger',\n",
       " 'mention',\n",
       " 'assez',\n",
       " 'bien',\n",
       " '2014',\n",
       " 'maitrise',\n",
       " 'mathématiques',\n",
       " 'appliquées',\n",
       " 'informatique',\n",
       " 'université',\n",
       " 'gaston',\n",
       " 'berger',\n",
       " 'mention',\n",
       " 'assez',\n",
       " 'bien',\n",
       " '2010',\n",
       " 'baccalauréat',\n",
       " 'scientifique',\n",
       " 'mention',\n",
       " 'passable',\n",
       " 'langues',\n",
       " 'anglais',\n",
       " 'intermédiaire',\n",
       " 'français',\n",
       " 'courant',\n",
       " 'localisation',\n",
       " 'dakar',\n",
       " 'keur',\n",
       " 'massar',\n",
       " 'principales',\n",
       " 'compétences',\n",
       " 'conception',\n",
       " 'analyse',\n",
       " 'développement',\n",
       " 'compétences',\n",
       " 'analyse',\n",
       " 'cahier',\n",
       " 'charges',\n",
       " 'fonctionnelles',\n",
       " 'modélisation',\n",
       " 'données',\n",
       " 'modèle',\n",
       " 'entité',\n",
       " 'association',\n",
       " 'modélisation',\n",
       " 'objet',\n",
       " 'uml',\n",
       " 'développement',\n",
       " 'application',\n",
       " 'algorithme',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'compétences',\n",
       " 'techniques',\n",
       " 'domaine',\n",
       " 'niveau',\n",
       " 'domaine',\n",
       " 'niveau',\n",
       " 'langage',\n",
       " 'framework',\n",
       " 'bdd',\n",
       " 'sql',\n",
       " 'sql',\n",
       " '2',\n",
       " 'javascript',\n",
       " '2',\n",
       " 'server',\n",
       " 'jquery',\n",
       " 'postgresql',\n",
       " 'python',\n",
       " 'c',\n",
       " 'c',\n",
       " '1',\n",
       " '5',\n",
       " 'intégration',\n",
       " 'html',\n",
       " '2',\n",
       " 'css',\n",
       " 'java',\n",
       " 'java',\n",
       " 'jee',\n",
       " '2',\n",
       " 'php',\n",
       " 'bootstrap',\n",
       " '2',\n",
       " 'symfony',\n",
       " '1',\n",
       " '5',\n",
       " 'django',\n",
       " '1',\n",
       " 'systèmes',\n",
       " 'exploitation',\n",
       " 'linux',\n",
       " '2',\n",
       " 'windows',\n",
       " '2',\n",
       " '5',\n",
       " 'outils',\n",
       " 'maven',\n",
       " '1',\n",
       " 'uipath',\n",
       " '2',\n",
       " '5',\n",
       " 'tomcat',\n",
       " '2',\n",
       " '2',\n",
       " 'jboss',\n",
       " 'wildfly',\n",
       " '1',\n",
       " '5',\n",
       " 'rpa',\n",
       " 'express',\n",
       " 'zeplin',\n",
       " 'modélisation',\n",
       " 'uml',\n",
       " 'bpmn',\n",
       " '2',\n",
       " 'mathématiques',\n",
       " 'atos',\n",
       " 'déc',\n",
       " '2018',\n",
       " 'aujourd',\n",
       " 'hui',\n",
       " 'covoiturage',\n",
       " 'fonction',\n",
       " 'développeur',\n",
       " 'backend',\n",
       " 'projet',\n",
       " 'développement',\n",
       " 'application',\n",
       " 'covoiturage',\n",
       " 'mission',\n",
       " 'analyse',\n",
       " 'besoins',\n",
       " 'conception',\n",
       " 'réalisations',\n",
       " 'développement',\n",
       " 'application',\n",
       " 'déploiement',\n",
       " 'environnement',\n",
       " 'java',\n",
       " 'jee',\n",
       " 'jhipster',\n",
       " 'angular',\n",
       " 'html',\n",
       " 'css',\n",
       " 'maven',\n",
       " 'git',\n",
       " 'intelli',\n",
       " 'j',\n",
       " 'ionic',\n",
       " 'mysql',\n",
       " 'workbench',\n",
       " 'jdl',\n",
       " 'studio',\n",
       " 'atos',\n",
       " 'fev',\n",
       " '2017',\n",
       " 'déc',\n",
       " '2018',\n",
       " 'système',\n",
       " 'recommandation',\n",
       " 'fonction',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'projet',\n",
       " 'développement',\n",
       " 'système',\n",
       " 'recommandation',\n",
       " 'profil',\n",
       " 'mission',\n",
       " 'analyse',\n",
       " 'besoins',\n",
       " 'conception',\n",
       " 'réalisations',\n",
       " 'développement',\n",
       " 'partie',\n",
       " 'backend',\n",
       " 'python',\n",
       " 'développement',\n",
       " 'partie',\n",
       " 'front',\n",
       " 'angular',\n",
       " 'environnement',\n",
       " 'python',\n",
       " 'flask',\n",
       " 'angular',\n",
       " 'html',\n",
       " 'css',\n",
       " 'material',\n",
       " 'design',\n",
       " 'visual',\n",
       " 'studio',\n",
       " 'code',\n",
       " 'dimbl',\n",
       " 'holding',\n",
       " 'service',\n",
       " 'fev',\n",
       " '2017',\n",
       " 'juillet',\n",
       " 'développement',\n",
       " 'algorithme',\n",
       " '2017',\n",
       " 'fonction',\n",
       " 'stagiaire',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'projet',\n",
       " 'développement',\n",
       " 'algorithme',\n",
       " 'scraping',\n",
       " 'rebot',\n",
       " 'collecte',\n",
       " 'données',\n",
       " 'sites',\n",
       " 'web',\n",
       " 'mission',\n",
       " 'développer',\n",
       " 'algorithmes',\n",
       " 'collecte',\n",
       " 'données',\n",
       " 'réalisations',\n",
       " 'comparaison',\n",
       " 'programme',\n",
       " 'écrit',\n",
       " 'python',\n",
       " 'celui',\n",
       " 'écrit',\n",
       " 'c',\n",
       " 'environnement',\n",
       " 'r',\n",
       " 'python',\n",
       " 'c',\n",
       " 'certifications',\n",
       " 'microsoft',\n",
       " 'programming',\n",
       " 'in',\n",
       " 'html5',\n",
       " 'with',\n",
       " 'javascript',\n",
       " 'and',\n",
       " 'css3',\n",
       " 'examen',\n",
       " '70',\n",
       " '480',\n",
       " 'oracle',\n",
       " 'certified',\n",
       " 'associate',\n",
       " 'java',\n",
       " 'programmer',\n",
       " 'oca',\n",
       " 'en',\n",
       " 'cour',\n",
       " 'centre',\n",
       " 'intérêt',\n",
       " 'jogging',\n",
       " 'football',\n",
       " 'lecture']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter \n",
    "\n",
    "\n",
    "\n",
    "train,test =  dataset[0:11],dataset[11:]\n",
    "\n",
    "#2 tokenize : remove all no alphanumeric character and remove stopwords\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def dataCleaning(raw_data):\n",
    "    cleaned_data = []\n",
    "    stop_words = set(stopwords.words(\"french\"))\n",
    "    for data in raw_data:\n",
    "        cleaned_data.append([x.lower() for x in tokenizer.tokenize(data) if x not in stop_words])\n",
    "    return cleaned_data;\n",
    "\n",
    "train = dataCleaning(train)\n",
    "\n",
    "occurences  = Counter(train[0])\n",
    "\n",
    "train[0]\n",
    "train_ = re.sub(\"[\\\\r\\\\n\\|]*\",\"\",train[0])\n",
    "train_ = re.sub(\"[\\\\s]{2,*}\",\"\",train_)\n",
    "train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordDoc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3406c844e7be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtableToDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordDoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wordDoc' is not defined"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#transform word table to pandas dataframe\n",
    "def tableToDF(wordDoc):\n",
    "    tables = []\n",
    "    for table in wordDoc.tables:\n",
    "        df = [['' for i in range(len(table.columns))] for j in range(len(table.rows))]\n",
    "        for i, row in enumerate(table.rows):\n",
    "            for j, cell in enumerate(row.cells):\n",
    "                if cell.text:\n",
    "                    df[i][j] = cell.text\n",
    "        tables.append(pd.DataFrame(df))\n",
    "    return tables;\n",
    "\n",
    "res = tableToDF(wordDoc)\n",
    "print(len(res))\n",
    "res[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = u\"./resume_sentence_dataset.json\"\n",
    "\n",
    "\n",
    "data = pd.read_csv(filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
